{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e733e7fc-d2b6-4293-97e9-9d4e97c85f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc346ef1-6308-48c3-99dd-7aa120742ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 228145 characters, 27 unique.\n",
      "----\n",
      " psstnijehfanvzppjadplqxubhauacuecwuogdffjep\n",
      "oloskbrzye\n",
      "qtlczdbkvdjgpbndalwcy\n",
      "ozmkvemejksjujzrqdz\n",
      "tvmshdounyxmfzwdsogjeupjrhedeeffckmdjybbd\n",
      "awwvitzzvlfkxhvceuluobgkvqlpqptcicykahvjbbccazqggbu\n",
      "xwxziczrw \n",
      "----\n",
      "iter 0, loss: 82.395919\n",
      "----\n",
      " nm\n",
      "ueianranallfsryemaieg\n",
      "\n",
      "zrcnlw\n",
      "ieidi\n",
      "sdaniiibkei\n",
      "nryaa\n",
      "rpalgey\n",
      "elsaylicjemlloagyxnfy\n",
      "alwdy\n",
      "ylaxy\n",
      "inazseellgyq\n",
      "da\n",
      "h\n",
      "a\n",
      "iaialhmdn\n",
      "iyn\n",
      "vlrlj\n",
      "ey\n",
      "uaxaxafiirnylnrhtnegr\n",
      "\n",
      "iiilodwllargrle\n",
      "re\n",
      "zlxh\n",
      "mui\n",
      "qvpalan \n",
      "----\n",
      "iter 100, loss: 83.204746\n",
      "----\n",
      " iya\n",
      "imiyeranjta\n",
      "ryinh\n",
      "aay\n",
      "ayajyle\n",
      "kaanr\n",
      "b\n",
      "a\n",
      "rya\n",
      "iai\n",
      "iidaejjoan\n",
      "yanlpi\n",
      "joi\n",
      "ocoielo\n",
      "beigineye\n",
      "rmand\n",
      "laah\n",
      "\n",
      "eyi\n",
      "e\n",
      "anemnnmla\n",
      "imxma\n",
      "y\n",
      "aulyi\n",
      "ebe\n",
      "anaia\n",
      "hiirlaiam\n",
      "ialti\n",
      "imiai\n",
      "eynainc\n",
      "aoilina\n",
      "a\n",
      "iaann\n",
      "nyinh\n",
      "bei\n",
      " \n",
      "----\n",
      "iter 200, loss: 81.866089\n",
      "----\n",
      " \n",
      "ya\n",
      "afkba\n",
      "ejeip\n",
      "aliledna\n",
      "joa\n",
      "piymlma\n",
      "\n",
      "jpthnsosra\n",
      "joer\n",
      "xs\n",
      "vaarir\n",
      "tlayl\n",
      "rsrye\n",
      "anealnasgaele\n",
      "flia\n",
      "aakrvna\n",
      "saagarna\n",
      "tslae\n",
      "aktiese\n",
      "iiiy\n",
      "arat\n",
      "eyo\n",
      "esassyn\n",
      "jia\n",
      "tsart\n",
      "ajia\n",
      "padiirheh\n",
      "mrsrbi\n",
      "estsra\n",
      "sisedrlc\n",
      "oamu \n",
      "----\n",
      "iter 300, loss: 80.198452\n",
      "----\n",
      " paooide\n",
      "dsa\n",
      "kocphn\n",
      "ablinsnanena\n",
      "aniv\n",
      "zelann\n",
      "liara\n",
      "jjwlancan\n",
      "elrsan\n",
      "kanyia\n",
      "bablernnsny\n",
      "adijiqa\n",
      "kowhngwawjanaffneleun\n",
      "sictu\n",
      "aiwneey\n",
      "mortaan\n",
      "kdinay\n",
      "danekatazaxbrinir\n",
      "\n",
      "oaexa\n",
      "aoloehsnl\n",
      "llityn\n",
      "sirlainacfafr \n",
      "----\n",
      "iter 400, loss: 78.593601\n",
      "----\n",
      " zornali\n",
      "ftaycalna\n",
      "ioaszehaca\n",
      "keine\n",
      "ebmajeracenzn\n",
      "a\n",
      "uziynfnaa\n",
      "kaala\n",
      "bygoitlhne\n",
      "cualili\n",
      "zmenrnanra\n",
      "jawlhrn\n",
      "aratkzi\n",
      "myeeg\n",
      "jilen\n",
      "karalen\n",
      "zaeratnh\n",
      "opelinrky\n",
      "cninli\n",
      "aolvdi\n",
      "ka\n",
      "tksa\n",
      "rnzieneti\n",
      "rirlen\n",
      "zaefeyn\n",
      "c \n",
      "----\n",
      "iter 500, loss: 76.952302\n",
      "----\n",
      " nlsa\n",
      "ara\n",
      "lyo\n",
      "amash\n",
      "iily\n",
      "hcalai\n",
      "bselenont\n",
      "mrani\n",
      "sceny\n",
      "ecane\n",
      "carecdanate\n",
      "alata\n",
      "agyan\n",
      "mtivane\n",
      "sbosinit\n",
      "aasanledlelhn\n",
      "tenlisan\n",
      "jborlaeny\n",
      "oafei\n",
      "mofren\n",
      "halini\n",
      "nnelena\n",
      "errvlel\n",
      "lttst\n",
      "mnere\n",
      "rroye\n",
      "bsitighie\n",
      "sli \n",
      "----\n",
      "iter 600, loss: 75.486329\n",
      "----\n",
      " rtiire\n",
      "dblit\n",
      "neoy\n",
      "\n",
      "yneyn\n",
      "cjaaria\n",
      "dieh\n",
      "dvnysdy\n",
      "dottcran\n",
      "avzil\n",
      "emyoay\n",
      "etuula\n",
      "jariniy\n",
      "bwtysly\n",
      "ka\n",
      "merily\n",
      "janilia\n",
      "htnali\n",
      "la\n",
      "vmap\n",
      "roraa\n",
      "jaijalpy\n",
      "aaria\n",
      "eaeda\n",
      "aaula\n",
      "jeinela\n",
      "hagaa\n",
      "akeesau\n",
      "aleryn\n",
      "miauliek\n",
      "anory \n",
      "----\n",
      "iter 700, loss: 74.161613\n",
      "----\n",
      " ydas\n",
      "otaroxte\n",
      "eatyeara\n",
      "kesyy\n",
      "malynnanh\n",
      "amatliw\n",
      "anynsa\n",
      "kally\n",
      "zsetei\n",
      "saahdba\n",
      "alanle\n",
      "nakiyan\n",
      "ararana\n",
      "nakae\n",
      "a\n",
      "alli\n",
      "anriyn\n",
      "eaimhsi\n",
      "maelye\n",
      "nara\n",
      "adismiy\n",
      "caleniy\n",
      "jrei\n",
      "anhyla\n",
      "karayve\n",
      "mayna\n",
      "narhnlilh\n",
      "jmerhyx\n",
      "ka \n",
      "----\n",
      "iter 800, loss: 72.775595\n",
      "----\n",
      " vra\n",
      "harala\n",
      "lala\n",
      "ejileyn\n",
      "sanan\n",
      "eliti\n",
      "bgcityn\n",
      "garezae\n",
      "kamoraa\n",
      "aran\n",
      "azluy\n",
      "ylintre\n",
      "e\n",
      "dyela\n",
      "teryni\n",
      "lmnana\n",
      "ania\n",
      "alryh\n",
      "cae\n",
      "vamyy\n",
      "ilaanma\n",
      "bznina\n",
      "fbwlyn\n",
      "va\n",
      "abnayla\n",
      "anetlila\n",
      "aliyn\n",
      "veeyca\n",
      "jronat\n",
      "bana\n",
      "buelsyd\n",
      "sol \n",
      "----\n",
      "iter 900, loss: 71.496792\n",
      "----\n",
      " mamen\n",
      "balei\n",
      "\n",
      "anslea\n",
      "lorahe\n",
      "haalan\n",
      "amainlleg\n",
      "sakae\n",
      "marea\n",
      "jyanba\n",
      "wernen\n",
      "atii\n",
      "akewame\n",
      "naleelyn\n",
      "keleka\n",
      "aualyh\n",
      "kyrnia\n",
      "adeillan\n",
      "eriei\n",
      "ozuva\n",
      "kamelin\n",
      "asarewi\n",
      "\n",
      "chnnan\n",
      "naielan\n",
      "joray\n",
      "dligi\n",
      "cecenea\n",
      "kamoula\n",
      "naire\n",
      " \n",
      "----\n",
      "iter 1000, loss: 70.329644\n",
      "----\n",
      " \n",
      "helihe\n",
      "katon\n",
      "ebmeyla\n",
      "eluys\n",
      "lanra\n",
      "jaliran\n",
      "joela\n",
      "vyelisa\n",
      "laela\n",
      "lien\n",
      "ahedi\n",
      "mabsonr\n",
      "emasiy\n",
      "zenaa\n",
      "altolhnn\n",
      "mianirlna\n",
      "bpyl\n",
      "ameta\n",
      "jinata\n",
      "rsohag\n",
      "sonafa\n",
      "radah\n",
      "helisyn\n",
      "hallash\n",
      "etirepa\n",
      "aadvinala\n",
      "habyalpa\n",
      "jaanyh \n",
      "----\n",
      "iter 1100, loss: 69.276323\n",
      "----\n",
      " a\n",
      "zoeina\n",
      "skoalala\n",
      "bzalee\n",
      "dailil\n",
      "ifalene\n",
      "elran\n",
      "lhalilan\n",
      "eleel\n",
      "kerlen\n",
      "lerese\n",
      "sarakda\n",
      "masyna\n",
      "ekyinabgye\n",
      "ihadsany\n",
      "kyimsta\n",
      "cdettor\n",
      "aovri\n",
      "eluyn\n",
      "miyi\n",
      "ryula\n",
      "jinhi\n",
      "sabrrei\n",
      "iosadie\n",
      "llerhiya\n",
      "caliadni\n",
      "karaen\n",
      "moed \n",
      "----\n",
      "iter 1200, loss: 68.283179\n",
      "----\n",
      " \n",
      "suedena\n",
      "matdannan\n",
      "lenah\n",
      "aarne\n",
      "casrane\n",
      "sanruy\n",
      "mamna\n",
      "oydmya\n",
      "kela\n",
      "baden\n",
      "tallama\n",
      "enerie\n",
      "fanana\n",
      "tilenene\n",
      "kraltic\n",
      "kadhe\n",
      "kfaly\n",
      "cakailieh\n",
      "gaglyia\n",
      "mayrie\n",
      "abfeyn\n",
      "tiaiba\n",
      "anenae\n",
      "iareynn\n",
      "kosi\n",
      "lelar\n",
      "cnalinvi\n",
      "kannn \n",
      "----\n",
      "iter 1300, loss: 67.366035\n",
      "----\n",
      " yya\n",
      "jaidin\n",
      "pbmanyh\n",
      "rieya\n",
      "saeriy\n",
      "azianan\n",
      "apalia\n",
      "histpan\n",
      "marketa\n",
      "latnirp\n",
      "jehiha\n",
      "semenh\n",
      "eminsa\n",
      "laysa\n",
      "muravelh\n",
      "lamis\n",
      "caniy\n",
      "jfarionah\n",
      "liha\n",
      "mianqlyy\n",
      "soriag\n",
      "teli\n",
      "ymeyba\n",
      "gsyylla\n",
      "jaava\n",
      "bamalinh\n",
      "jadah\n",
      "caya\n",
      "mine \n",
      "----\n",
      "iter 1400, loss: 66.554378\n",
      "----\n",
      " a\n",
      "mordidi\n",
      "ciranaa\n",
      "syablui\n",
      "arrisha\n",
      "maries\n",
      "kemaril\n",
      "acuis\n",
      "imalhi\n",
      "bhieni\n",
      "ssreranah\n",
      "yealiana\n",
      "kmoilyl\n",
      "cesllaah\n",
      "aehau\n",
      "mlosus\n",
      "enanazenanna\n",
      "vady\n",
      "jacvah\n",
      "ashiat\n",
      "pkaenyn\n",
      "sai\n",
      "jenia\n",
      "mrenedt\n",
      "bmaxah\n",
      "allevah\n",
      "manah\n",
      "nli \n",
      "----\n",
      "iter 1500, loss: 65.788161\n",
      "----\n",
      " kolir\n",
      "kaihl\n",
      "ecnalan\n",
      "eylal\n",
      "kaohlina\n",
      "azanana\n",
      "dpamyni\n",
      "mechor\n",
      "jofolenen\n",
      "jideling\n",
      "jrin\n",
      "komye\n",
      "ialili\n",
      "allyal\n",
      "nrikeo\n",
      "gienan\n",
      "larabre\n",
      "kyelyay\n",
      "ezana\n",
      "cnrenh\n",
      "fohlelli\n",
      "aanaara\n",
      "jalanay\n",
      "tiee\n",
      "ayalaa\n",
      "celle\n",
      "rllina\n",
      "omaji \n",
      "----\n",
      "iter 1600, loss: 65.155622\n",
      "----\n",
      " eranin\n",
      "aileztoe\n",
      "zrirah\n",
      "rlkensan\n",
      "losee\n",
      "sessina\n",
      "kaeri\n",
      "bufai\n",
      "arilo\n",
      "hneil\n",
      "bviig\n",
      "ewait\n",
      "avile\n",
      "weea\n",
      "xhrehna\n",
      "asdeney\n",
      "miiaa\n",
      "omhyziea\n",
      "ledannl\n",
      "rmenyeh\n",
      "anezy\n",
      "myarit\n",
      "fselina\n",
      "britnen\n",
      "marria\n",
      "areyy\n",
      "sripe\n",
      "breqiiske\n",
      "ma \n",
      "----\n",
      "iter 1700, loss: 64.478137\n",
      "----\n",
      " \n",
      "rana\n",
      "adilan\n",
      "yariu\n",
      "locza\n",
      "kariyn\n",
      "jyana\n",
      "ililan\n",
      "bria\n",
      "anynnn\n",
      "hrlyi\n",
      "jarae\n",
      "kamx\n",
      "valann\n",
      "erlyn\n",
      "hanava\n",
      "acavan\n",
      "tayimelan\n",
      "jaaryrla\n",
      "atisiyag\n",
      "manrlecyn\n",
      "aralii\n",
      "miladyn\n",
      "sorlsa\n",
      "dtelel\n",
      "arari\n",
      "craarli\n",
      "zaryann\n",
      "elen\n",
      "adzru \n",
      "----\n",
      "iter 1800, loss: 63.844713\n",
      "----\n",
      " yt\n",
      "mrieh\n",
      "koana\n",
      "mazdoet\n",
      "tyise\n",
      "cyira\n",
      "twiyselnanah\n",
      "acuarinn\n",
      "emanali\n",
      "meeli\n",
      "oazalea\n",
      "arnro\n",
      "sothtya\n",
      "mrerh\n",
      "tiern\n",
      "arorosa\n",
      "oilin\n",
      "menisle\n",
      "dkela\n",
      "vradien\n",
      "oromey\n",
      "airinn\n",
      "tyoecna\n",
      "kesiy\n",
      "mydlieya\n",
      "rarira\n",
      "balizliana\n",
      "canl \n",
      "----\n",
      "iter 1900, loss: 63.412067\n",
      "----\n",
      " ma\n",
      "usjai\n",
      "karasen\n",
      "aenlil\n",
      "sbynen\n",
      "ayann\n",
      "kaniah\n",
      "jamdoglo\n",
      "maibrie\n",
      "haclihth\n",
      "bhelir\n",
      "amieh\n",
      "keha\n",
      "slzannsa\n",
      "llielons\n",
      "jethale\n",
      "fhylilsa\n",
      "ally\n",
      "mad\n",
      "zustaan\n",
      "samie\n",
      "rlullele\n",
      "naahvin\n",
      "aehnelef\n",
      "loeigh\n",
      "halla\n",
      "caith\n",
      "adisina\n",
      "c \n",
      "----\n",
      "iter 2000, loss: 62.920891\n",
      "----\n",
      " nah\n",
      "ozbeninnlia\n",
      "ceiynka\n",
      "krissha\n",
      "keilohi\n",
      "ajial\n",
      "adnel\n",
      "sarena\n",
      "ynery\n",
      "mokalha\n",
      "kaylax\n",
      "bazssemra\n",
      "gefsmea\n",
      "sazel\n",
      "afhyylie\n",
      "halailaca\n",
      "daita\n",
      "dralia\n",
      "jakellan\n",
      "etainne\n",
      "dietha\n",
      "alixla\n",
      "ekalalyn\n",
      "koszih\n",
      "lahinih\n",
      "hcaloaha\n",
      " \n",
      "----\n",
      "iter 2100, loss: 62.306536\n",
      "----\n",
      " len\n",
      "iraezere\n",
      "wareletnnh\n",
      "sariy\n",
      "areleip\n",
      "jerya\n",
      "bo\n",
      "erlea\n",
      "yalheg\n",
      "leisnisleh\n",
      "leria\n",
      "naleeea\n",
      "rotamalae\n",
      "slamassca\n",
      "darouanonn\n",
      "fymy\n",
      "tzeva\n",
      "llyi\n",
      "mamnana\n",
      "muyhs\n",
      "hopimaian\n",
      "sauleke\n",
      "myela\n",
      "trrien\n",
      "ljia\n",
      "slena\n",
      "minai\n",
      "zaaled \n",
      "----\n",
      "iter 2200, loss: 61.863682\n",
      "----\n",
      " yni\n",
      "tiadlet\n",
      "fieni\n",
      "jao\n",
      "habuti\n",
      "stayn\n",
      "sliyi\n",
      "abslo\n",
      "kaytsyy\n",
      "drarlalah\n",
      "ieclanna\n",
      "tnyrijoa\n",
      "ziseyaa\n",
      "elahannne\n",
      "calimman\n",
      "zaisemaa\n",
      "maisy\n",
      "utidot\n",
      "glena\n",
      "lyna\n",
      "erli\n",
      "kejita\n",
      "leleh\n",
      "htylea\n",
      "ccila\n",
      "faunrate\n",
      "alailh\n",
      "kacbmi\n",
      "mye \n",
      "----\n",
      "iter 2300, loss: 61.452125\n",
      "----\n",
      " akal\n",
      "maalyn\n",
      "jannedi\n",
      "jany\n",
      "apdama\n",
      "maencan\n",
      "avillen\n",
      "arateah\n",
      "keneha\n",
      "karyth\n",
      "maara\n",
      "avit\n",
      "herilse\n",
      "kema\n",
      "memna\n",
      "aayyn\n",
      "karya\n",
      "doula\n",
      "riynya\n",
      "lavoi\n",
      "bemiyhla\n",
      "yviama\n",
      "aode\n",
      "ytmenid\n",
      "mliig\n",
      "mmeel\n",
      "azyan\n",
      "reika\n",
      "emyie\n",
      "kynen\n",
      "eana \n",
      "----\n",
      "iter 2400, loss: 60.953622\n",
      "----\n",
      " lwh\n",
      "belyna\n",
      "brlenrely\n",
      "nreshy\n",
      "deava\n",
      "driilyn\n",
      "meani\n",
      "revata\n",
      "faro\n",
      "rarlezi\n",
      "joria\n",
      "drphennad\n",
      "oslona\n",
      "hyamai\n",
      "bhye\n",
      "kaiafle\n",
      "shamenle\n",
      "kava\n",
      "rouih\n",
      "majsanga\n",
      "cobros\n",
      "avameyna\n",
      "daselria\n",
      "bila\n",
      "slytiha\n",
      "esyn\n",
      "nekisgea\n",
      "ear\n",
      "rrin \n",
      "----\n",
      "iter 2500, loss: 60.668364\n",
      "----\n",
      " \n",
      "helaan\n",
      "monyfa\n",
      "ernyenna\n",
      "daenyn\n",
      "anniki\n",
      "abreley\n",
      "aalinon\n",
      "samneail\n",
      "eighanah\n",
      "amala\n",
      "yiah\n",
      "erirce\n",
      "teyin\n",
      "alicena\n",
      "korii\n",
      "oyyancp\n",
      "zosoy\n",
      "yajlity\n",
      "ahnvi\n",
      "jasleesly\n",
      "chanah\n",
      "rersoni\n",
      "cogahy\n",
      "sezoy\n",
      "i\n",
      "asamalan\n",
      "eina\n",
      "srynaa\n",
      "d \n",
      "----\n",
      "iter 2600, loss: 60.288941\n",
      "----\n",
      " yn\n",
      "jiania\n",
      "eiqne\n",
      "ecuxle\n",
      "jarla\n",
      "korya\n",
      "slyyayele\n",
      "jamriee\n",
      "nana\n",
      "riolin\n",
      "ceiyo\n",
      "foenet\n",
      "jadar\n",
      "emistle\n",
      "jarine\n",
      "avynr\n",
      "eanahily\n",
      "aleeynas\n",
      "eyanni\n",
      "zauay\n",
      "powielah\n",
      "nderice\n",
      "jeibwy\n",
      "arbrie\n",
      "kaylali\n",
      "dafliki\n",
      "kerilyalin\n",
      "esevy\n",
      " \n",
      "----\n",
      "iter 2700, loss: 59.812300\n",
      "----\n",
      " ina\n",
      "lyet\n",
      "inorisa\n",
      "nyannsi\n",
      "hauhna\n",
      "alhiista\n",
      "antadaga\n",
      "darmyn\n",
      "zolianla\n",
      "rexite\n",
      "matmianny\n",
      "ahaninbeh\n",
      "annn\n",
      "luryna\n",
      "argyn\n",
      "maa\n",
      "lisai\n",
      "zaniseac\n",
      "riala\n",
      "arinsy\n",
      "itusunie\n",
      "kaulygha\n",
      "naumome\n",
      "yziti\n",
      "caain\n",
      "malyva\n",
      "alsatfay\n",
      "jao \n",
      "----\n",
      "iter 2800, loss: 59.643183\n",
      "----\n",
      " e\n",
      "gviie\n",
      "darreda\n",
      "kophina\n",
      "burie\n",
      "celile\n",
      "klian\n",
      "ehasonyn\n",
      "dalelealry\n",
      "sauazi\n",
      "fooehe\n",
      "fureisesah\n",
      "mellae\n",
      "aeys\n",
      "supdea\n",
      "kavokr\n",
      "xadalia\n",
      "ramila\n",
      "reruyn\n",
      "terica\n",
      "jeeyn\n",
      "jye\n",
      "karhjo\n",
      "zshluel\n",
      "anay\n",
      "sene\n",
      "jysai\n",
      "mykanys\n",
      "jacahi\n",
      "k \n",
      "----\n",
      "iter 2900, loss: 59.374187\n",
      "----\n",
      " uys\n",
      "qewesh\n",
      "byuveyli\n",
      "danilh\n",
      "hlelaih\n",
      "vurvy\n",
      "zananne\n",
      "lemmeslte\n",
      "naivelie\n",
      "kemya\n",
      "erlei\n",
      "adcay\n",
      "omyada\n",
      "kanlae\n",
      "zyyay\n",
      "eylavep\n",
      "yadag\n",
      "celesy\n",
      "zimmavesh\n",
      "haraalh\n",
      "keeyahi\n",
      "priee\n",
      "tunyn\n",
      "zadeenh\n",
      "alisana\n",
      "ianloyaa\n",
      "zreanni\n",
      "va \n",
      "----\n",
      "iter 3000, loss: 59.344906\n",
      "----\n",
      " nlele\n",
      "ararely\n",
      "calinah\n",
      "fobeh\n",
      "simawya\n",
      "azanie\n",
      "cenlien\n",
      "ianlali\n",
      "jviemyah\n",
      "adelanni\n",
      "ylalienan\n",
      "ryrya\n",
      "aviyna\n",
      "sacinn\n",
      "hstalai\n",
      "lellidseahneahie\n",
      "lonesina\n",
      "thesye\n",
      "kahyn\n",
      "daictosh\n",
      "ianna\n",
      "ativean\n",
      "etdydi\n",
      "casyh\n",
      "bedaha\n",
      "nan \n",
      "----\n",
      "iter 3100, loss: 59.108541\n",
      "----\n",
      " tarh\n",
      "milannaa\n",
      "kamdistia\n",
      "umiai\n",
      "jutyyl\n",
      "malkanyn\n",
      "anarior\n",
      "alanieah\n",
      "ealiah\n",
      "jyandellie\n",
      "plyke\n",
      "mayy\n",
      "lyanay\n",
      "mbisein\n",
      "bnozhha\n",
      "relie\n",
      "maalah\n",
      "anrore\n",
      "bhamgan\n",
      "stiaxna\n",
      "pmelyn\n",
      "kertie\n",
      "malin\n",
      "mien\n",
      "matida\n",
      "elien\n",
      "tuyennn\n",
      "han \n",
      "----\n",
      "iter 3200, loss: 58.756075\n",
      "----\n",
      " h\n",
      "jornanan\n",
      "loqgya\n",
      "folya\n",
      "derrie\n",
      "assanylona\n",
      "alya\n",
      "kaliy\n",
      "ciavabeiaah\n",
      "mamiinnea\n",
      "yinayah\n",
      "lanalya\n",
      "losby\n",
      "abiinama\n",
      "beynra\n",
      "qalena\n",
      "bdbmy\n",
      "lailaebenna\n",
      "adisenah\n",
      "khlelyn\n",
      "live\n",
      "alie\n",
      "aeza\n",
      "biazbuinay\n",
      "ahaazali\n",
      "danah\n",
      "gren \n",
      "----\n",
      "iter 3300, loss: 58.557642\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (txt, ))\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# forward seq_length characters through the net and fetch gradient\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m loss, dWxh, dWhh, dWhy, dbh, dby, hprev \u001b[38;5;241m=\u001b[39m \u001b[43mlossFun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhprev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m smooth_loss \u001b[38;5;241m=\u001b[39m smooth_loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.999\u001b[39m \u001b[38;5;241m+\u001b[39m loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m, in \u001b[0;36mlossFun\u001b[0;34m(inputs, targets, hprev)\u001b[0m\n\u001b[1;32m     34\u001b[0m xs[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((vocab_size,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# encode in 1-of-k representation\u001b[39;00m\n\u001b[1;32m     35\u001b[0m xs[t][inputs[t]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 36\u001b[0m hs[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(np\u001b[38;5;241m.\u001b[39mdot(Wxh, xs[t]) \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWhh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m bh) \u001b[38;5;66;03m# hidden state\u001b[39;00m\n\u001b[1;32m     37\u001b[0m ys[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(Why, hs[t]) \u001b[38;5;241m+\u001b[39m by \u001b[38;5;66;03m# unnormalized log probabilities for next chars\u001b[39;00m\n\u001b[1;32m     38\u001b[0m ps[t] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(ys[t]) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mexp(ys[t])) \u001b[38;5;66;03m# probabilities for next chars\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data I/O\n",
    "data = open('names.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "# hyperparameters\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "def lossFun(inputs, targets, hprev):\n",
    "  \"\"\"\n",
    "  inputs,targets are both list of integers.\n",
    "  hprev is Hx1 array of initial hidden state\n",
    "  returns the loss, gradients on model parameters, and last hidden state\n",
    "  \"\"\"\n",
    "  xs, hs, ys, ps = {}, {}, {}, {}\n",
    "  hs[-1] = np.copy(hprev)\n",
    "  loss = 0\n",
    "  # forward pass\n",
    "  for t in range(len(inputs)):\n",
    "    xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "    xs[t][inputs[t]] = 1\n",
    "    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "    loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
    "  # backward pass: compute gradients going backwards\n",
    "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "  dhnext = np.zeros_like(hs[0])\n",
    "  for t in reversed(range(len(inputs))):\n",
    "    dy = np.copy(ps[t])\n",
    "    dy[targets[t]] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
    "    dWhy += np.dot(dy, hs[t].T)\n",
    "    dby += dy\n",
    "    dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "    dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "    dbh += dhraw\n",
    "    dWxh += np.dot(dhraw, xs[t].T)\n",
    "    dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "    dhnext = np.dot(Whh.T, dhraw)\n",
    "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "\n",
    "def sample(h, seed_ix, n):\n",
    "  \"\"\" \n",
    "  sample a sequence of integers from the model \n",
    "  h is memory state, seed_ix is seed letter for first time step\n",
    "  \"\"\"\n",
    "  x = np.zeros((vocab_size, 1))\n",
    "  x[seed_ix] = 1\n",
    "  ixes = []\n",
    "  for t in range(n):\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ixes.append(ix)\n",
    "  return ixes\n",
    "\n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "while True:\n",
    "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "  if p+seq_length+1 >= len(data) or n == 0: \n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    p = 0 # go from start of data\n",
    "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "  # sample from the model now and then\n",
    "  if n % 100 == 0:\n",
    "    sample_ix = sample(hprev, inputs[0], 200)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print('----\\n %s \\n----' % (txt, ))\n",
    "\n",
    "  # forward seq_length characters through the net and fetch gradient\n",
    "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "  if n % 100 == 0:\n",
    "      print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "  \n",
    "  # perform parameter update with Adagrad\n",
    "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "    mem += dparam * dparam\n",
    "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "  p += seq_length # move data pointer\n",
    "  n += 1 # iteration counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c3876-3638-475d-abf5-fcad6a363054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
