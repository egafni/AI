{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d97d3d7-aa7d-4ae4-b86d-232928c2e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "\n",
    "B=512\n",
    "C=128\n",
    "H=64\n",
    "T=8\n",
    "\n",
    "with open('../names.txt') as fp:\n",
    "    lines = fp.read()\n",
    "\n",
    "chars = sorted(set(lines))\n",
    "V = vocab_size = len(chars)\n",
    "ctoi = dict(zip(chars, range(vocab_size)))\n",
    "itoc = dict(zip(range(vocab_size), chars))\n",
    "data_ints = torch.tensor([ctoi[c] for c in lines ])\n",
    "\n",
    "def get_batch():\n",
    "    batch = []\n",
    "    for i in range(B):\n",
    "        idx = torch.randint(low=0,high=len(data_ints)-T-1,size=(1,))\n",
    "        batch.append(data_ints[idx:idx+T+1])\n",
    "\n",
    "    X = torch.vstack(batch)\n",
    "    y = X[:,1:].clone()\n",
    "    X = X[:,:-1]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2a800ce-607b-440a-b7d3-a42f2cbf3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, vocab_size):\n",
    "        super().__init__()\n",
    "        C=input_size\n",
    "        H=hidden_size\n",
    "        P = torch.nn.Parameter\n",
    "        self.W_xh = P(torch.randn(C, H) * np.sqrt(1/C))\n",
    "        self.W_hh = P(torch.randn(H, H) * np.sqrt(1/H))\n",
    "        self.b_h = P(torch.zeros(H))\n",
    "\n",
    "    def forward(self, x,h=None):\n",
    "        B, T, C = x.shape\n",
    "        if h is None:\n",
    "            h = torch.zeros(H)\n",
    "        logits = torch.zeros(T,B,vocab_size) # T,B,V\n",
    "        hts = []\n",
    "        for i in range(T):\n",
    "            h = torch.tanh(x[:,i,:]@self.W_xh + h@self.W_hh + self.b_h) # B,H\n",
    "            hts.append(h)\n",
    "        return torch.stack(hts).transpose(0,1).contiguous(), h # B,T,V        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81c86a3c-6ce6-4a85-95d0-7cb182182f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=C, hidden_size=H,bias=True,batch_first=True,bidirectional=True)\n",
    "# rnn = MyRNN(C,H,vocab_size)\n",
    "emb = torch.randn(vocab_size, C)\n",
    "W_hy = torch.randn(H, vocab_size) * np.sqrt(1/H)\n",
    "b_y = torch.zeros(vocab_size)\n",
    "\n",
    "params = [emb, W_hy, b_y] + list(rnn.parameters())\n",
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a166f3af-809e-4bbe-8cb7-7913f7b45e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=.01\n",
    "for i in range(1000):\n",
    "    X,y = get_batch()\n",
    "    o = emb[X]  # B,T,C\n",
    "    o2, h = rnn(o)\n",
    "    logits = o2@W_hy+b_y\n",
    "    # logits = forward(X)\n",
    "\n",
    "    \n",
    "    loss = F.cross_entropy(logits.view(B*T,V), y.view(B*T))\n",
    "    if i%100==0:\n",
    "        print(f'{loss:.4f}')\n",
    "\n",
    "    for param in params:\n",
    "        param.grad = None\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbe5eb-c68d-40be-8e77-267be94dbe2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bebf532-0895-4e0f-b8d0-9751d72e8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4847 myRnn\n",
    "# 2.5317 torch.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0f123c8-ab79-49f2-9876-afa39672ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmzzmr\n",
      "nmsceanll\n",
      "grrsmnmlrzrrernnlillrremfnlwlrwzl\n",
      "ylnrl\n",
      "nmysnmtnn\n",
      "lellnkwnlt\n",
      "rllrxf\n",
      "almvd\n",
      "rsirlnyer\n"
     ]
    }
   ],
   "source": [
    "prompt = lines[50:50+T]\n",
    "\n",
    "next_tokens = []\n",
    "for x in range(100):\n",
    "    [itoc[i] for i in next_tokens]\n",
    "    X_test = torch.tensor([ctoi[c] for c in prompt ])\n",
    "    X_test=X_test.unsqueeze(0)\n",
    "    o = emb[X_test]  # 1,T,C\n",
    "    o2, h = rnn(o)\n",
    "    logits = o2@W_hy + b_y\n",
    "    next_word_logits = logits[:,-1]\n",
    "    probas = F.softmax(next_word_logits, 1)\n",
    "    next_token = torch.multinomial(probas[0], 1)[0]\n",
    "    next_tokens.append(next_token.item())\n",
    "    X_test = X_test.roll(-1)\n",
    "    X_test[0,-1] = next_token\n",
    "print(''.join([itoc[i] for i in next_tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c51bde9e-5466-45a1-8955-209e873678dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0e834-b914-461a-8c07-b6f98ffb5ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
