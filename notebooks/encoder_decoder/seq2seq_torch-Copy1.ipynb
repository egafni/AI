{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0768cc2-13f4-43bc-bdeb-77651286fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ab5410-0fdd-4899-af70-ebba8641fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d148ad9e-9fb4-4975-8a6a-619280ea172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 141370 sentence pairs\n",
      "Trimmed to 119484 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "spa 12091\n",
      "eng 23395\n",
      "['don t eat between meals', 'no comas entre comidas', 'cc by france attribution tatoeba org ck hundo']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "    # and p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('spa', 'eng', False)\n",
    "print(random.choice(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54f4a2e-9e51-4cbb-ae2a-38f06662a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 141370 sentence pairs\n",
      "Trimmed to 119484 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "spa 12091\n",
      "eng 23395\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('spa', 'eng', False)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt,_) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader\n",
    "\n",
    "batch_size = 256\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df1b007-552d-48b9-9948-8b6f72e4bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d78daab-15bc-440d-ae3e-878f6c3ee702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        # decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, x, hidden):\n",
    "        output = self.embedding(x)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3800beb3-d541-49e1-84d5-e04150b505fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., -inf],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones(n_embd,n_embd)\n",
    "mask = mask.masked_fill(~torch.tril(mask).to(bool), -torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1221d63-8969-4273-8f3b-1180f10a208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        self.n_embd = n_embd\n",
    "        self.wq = nn.Linear(n_embd, n_embd)\n",
    "        self.wk = nn.Linear(n_embd, n_embd)\n",
    "        self.wv = nn.Linear(n_embd, n_embd)\n",
    "        causal_mask = torch.ones(n_embd,n_embd)\n",
    "        causal_mask = mask.masked_fill(~torch.tril(mask).to(bool), -torch.inf)\n",
    "        torch.register_buffer('causal_mask', causal_mask)\n",
    "    \n",
    "    def forward(self,q,k,v,mask,causal:bool): \n",
    "        # q: B,T1,C\n",
    "        # k: B,T2,C\n",
    "        # v: B,T2,C\n",
    "        q = self.wq(q) # B,T1,C\n",
    "        k = self.wk(k) # B,T2,C\n",
    "        v = self.wv(v) # B,T2,C\n",
    "        \n",
    "        weights = q@k.transpose(-1,-2) / math.sqrt(self.n_embd) # B,T1,T2\n",
    "        if causal:\n",
    "            weights *= self.causal_mask\n",
    "        attn = torch.softmax(weights) # B,T1,T2\n",
    "        x = attn @ v # B,T1,C\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, n_embd):\n",
    "        self.embedding = nn.Embedding(input_size, n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.attn = Attention(n_embd)\n",
    "        \n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.Relu(),\n",
    "            nn.Linear(n_embd*4, n_embd)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        o = self.embedding(x)\n",
    "        o = self.ln1(o)\n",
    "        o = self.attn(o,o,o,causal=True)\n",
    "        o = self.mlp(self.ln2(o))\n",
    "        return o\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, n_embd):\n",
    "        self.embedding = nn.Embedding(input_size, n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.attn = Attention(n_embd)\n",
    "\n",
    "        self.x_ln1 = nn.LayerNorm(n_embd)\n",
    "        self.x_attn = Attention(n_embd)\n",
    "        \n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.Relu(),\n",
    "            nn.Linear(n_embd*4, n_embd)\n",
    "        )\n",
    "\n",
    "    def forward(self,x,decoder_outputs):\n",
    "        o = self.embedding(x)\n",
    "        o = self.ln1(query=o,key=decoder_outputs,value=decoder_outputs,causal=)\n",
    "        o = self.attn()\n",
    "        o = self.mlp(self.ln2(o))\n",
    "        return o    \n",
    "        \n",
    "    # def forward(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44e44e2-8d42-4eb2-8c71-6f2c369e3d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "input_size = input_lang.n_words\n",
    "# hidden_size = 64\n",
    "n_embd = 32\n",
    "dropout=0.0\n",
    "output_size = output_lang.n_words\n",
    "encoder = Encoder(input_size, n_embd).to(device)\n",
    "decoder = DecoderRNN(n_embd, output_size).to(device)\n",
    "\n",
    "lr = 1e-2\n",
    "optim1 = AdamW(params=encoder.parameters(),lr=lr)\n",
    "optim2 = AdamW(params=decoder.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0c95139-a755-4e16-b67a-c89791252394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267e9016-512a-40b4-add3-5f191c05bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e0:s100 | loss:3.685\n",
      "e0:s200 | loss:3.442\n",
      "e0:s300 | loss:3.131\n",
      "e0:s400 | loss:3.014\n",
      "e1:s500 | loss:2.424\n",
      "e1:s600 | loss:2.297\n",
      "e1:s700 | loss:2.202\n",
      "e1:s800 | loss:2.075\n",
      "e1:s900 | loss:1.969\n",
      "e2:s1000 | loss:1.621\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m optim1\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m optim2\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optim1\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m optim2\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/mnt/ssd3/user/spock/.cache/pypoetry/virtualenvs/ai-iwSNfyWa-py3.10/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd3/user/spock/.cache/pypoetry/virtualenvs/ai-iwSNfyWa-py3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(10):\n",
    "    for X,y in train_dataloader:\n",
    "        step +=1\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        enc_outputs, enc_hidden = encoder(X)\n",
    "        decoder_outputs, decoder_hidden, _ = decoder(enc_outputs, enc_hidden, target_tensor=y)\n",
    "        loss = F.cross_entropy(decoder_outputs.view(-1, decoder_outputs.shape[-1]), y.view(-1))\n",
    "        if step % 100 == 0:\n",
    "            print(f'e{epoch}:s{step} | loss:{loss:.3f}')\n",
    "        optim1.zero_grad()\n",
    "        optim2.zero_grad()\n",
    "        loss.backward()\n",
    "        optim1.step()\n",
    "        optim2.step()\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e1b64e3-2847-4b94-b967-2ded9d0d5700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> thanks for waiting for me\n",
      "= gracias por esperarme\n",
      "< gracias por mi <EOS>\n",
      "\n",
      "> it was fun doing that\n",
      "= fue divertido hacerlo\n",
      "< fue facil que eso lo que eso <EOS>\n",
      "\n",
      "> tom doesn t seem to understand\n",
      "= tom parece no entender\n",
      "< tom no parece que entender <EOS>\n",
      "\n",
      "> they don t know yet\n",
      "= ellos todavia no lo saben\n",
      "< no sabemos no sabe <EOS>\n",
      "\n",
      "> she visits him twice a year\n",
      "= ella lo visita dos veces por ano\n",
      "< ella le dio una semana pasada <EOS>\n",
      "\n",
      "> you shouldn t see her now\n",
      "= sera mejor que no te encuentres con ella ahora\n",
      "< no deberias hablar a nadie ahora <EOS>\n",
      "\n",
      "> if it breaks it s no big deal\n",
      "= si se rompe no pasa nada\n",
      "< si si no se es tan grande <EOS>\n",
      "\n",
      "> how will you write it ?\n",
      "= como lo escribiras ?\n",
      "< como supiste ? <EOS>\n",
      "\n",
      "> i m going to go there\n",
      "= voy a ir alli\n",
      "< voy a ir a ir alla <EOS>\n",
      "\n",
      "> she danced with joy\n",
      "= ella bailaba de alegria\n",
      "< ella empezo a jugar al hospital <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        \n",
    "evaluateRandomly(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23767c-5829-4e74-b671-d8fbceb73d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3ad3b-0acf-4b3f-a32f-a3ae6e247239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
