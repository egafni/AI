{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0246732d-074e-4656-b40a-d73e170bc3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "import math \n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd56767-ec02-4942-921e-1c87d4200542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd3/user/spock/.cache/pypoetry/virtualenvs/ai-iwSNfyWa-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d6c0ec-69c5-4f5b-8bc7-99e4e863531a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.ones(5,5)*10\n",
    "X / X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73be4966-9edc-4cd3-b666-c0ec2030bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "291d51a4-6177-4e9d-aee1-7084f3c6f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a7551c-e30d-47b8-b691-611724cbfe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff65857-c716-43fe-9d26-a4300d5ea5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2, 5465,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [   2, 2227, 2572,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.transforms import PadTransform, Truncate, AddToken, VocabTransform, Sequential, ToTensor\n",
    "\n",
    "class Tokenize(nn.Module):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Do some transformations\n",
    "        return [self.tokenizer(sentence) for sentence in x]\n",
    "\n",
    "class Pad(nn.Module):\n",
    "    def __init__(self, length, pad_value):\n",
    "        super().__init__()\n",
    "        self.length = length\n",
    "        self.pad_value = pad_value \n",
    "\n",
    "    def forward(self, x):\n",
    "        # m = max(len(x_) for x_ in x)\n",
    "        def pad(x):        \n",
    "            if len(x) < self.length:\n",
    "                x += [self.pad_value] * (self.length - len(x))\n",
    "            return x\n",
    "            \n",
    "        return [pad(x_) for x_ in x]\n",
    "\n",
    "def get_preproc(token_transform, vocab_transform, max_seq_len):\n",
    "    # vocab = \n",
    "    return nn.Sequential(\n",
    "        Tokenize(token_transform),\n",
    "        VocabTransform(vocab_transform),\n",
    "        Truncate(max_seq_len=max_seq_len-2),\n",
    "        AddToken(BOS_IDX, begin=True),\n",
    "        AddToken(EOS_IDX, begin=False),\n",
    "        Pad(pad_value=PAD_IDX,length=max_seq_len),\n",
    "        ToTensor(),\n",
    "    )\n",
    "\n",
    "BLOCK_SIZE=64\n",
    "preproc_src = get_preproc(token_transform['de'],vocab_transform['de'], max_seq_len=BLOCK_SIZE)\n",
    "# can remove this +1 since last token is basically EOS\n",
    "preproc_tgt = get_preproc(token_transform['en'],vocab_transform['en'], max_seq_len=BLOCK_SIZE+1)\n",
    "preproc_tgt(['hello', 'my fellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b38b341-f771-417b-8242-48b6416c4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE)\n",
    "test_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "test_dataloader = DataLoader(test_iter, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65701148-a99f-4cc5-b9b3-119b05945df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.models.nlp.seq2seq.simple_attention import Encoder, Decoder\n",
    "device = torch.device('cuda')\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "n_embd=64\n",
    "encoder = Encoder(input_size=SRC_VOCAB_SIZE, n_embd=n_embd, max_block_size=BLOCK_SIZE).to(device)\n",
    "decoder = Decoder(output_vocab_size=TGT_VOCAB_SIZE, n_embd=n_embd, block_size=BLOCK_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3d88cd5-38f5-42b3-b5f6-cbad69297cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=.003\n",
    "optim1 = AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "366d888b-63c1-4a49-bccc-a06b4706d016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e0:s100 | loss:1.037\n",
      "e0:s200 | loss:0.934\n",
      "e0:s300 | loss:0.872\n",
      "e0:s400 | loss:0.871\n",
      "e0:s500 | loss:0.970\n",
      "e0:s600 | loss:0.783\n",
      "e0:s700 | loss:0.805\n",
      "e0:s800 | loss:0.953\n",
      "e0:s900 | loss:0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd3/user/spock/.cache/pypoetry/virtualenvs/ai-iwSNfyWa-py3.10/lib/python3.10/site-packages/torch/_jit_internal.py:1358: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1:s1000 | loss:0.671\n",
      "e1:s1100 | loss:0.676\n",
      "e1:s1200 | loss:0.683\n",
      "e1:s1300 | loss:0.553\n",
      "e1:s1400 | loss:0.727\n",
      "e1:s1500 | loss:0.649\n",
      "e1:s1600 | loss:0.659\n",
      "e1:s1700 | loss:0.737\n",
      "e1:s1800 | loss:0.641\n",
      "e2:s1900 | loss:0.652\n",
      "e2:s2000 | loss:0.580\n",
      "e2:s2100 | loss:0.651\n",
      "e2:s2200 | loss:0.492\n",
      "e2:s2300 | loss:0.587\n",
      "e2:s2400 | loss:0.592\n",
      "e2:s2500 | loss:0.623\n",
      "e2:s2600 | loss:0.659\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m optim1\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# optim2.zero_grad()\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optim1\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# optim2.step()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ssd3/user/spock/.cache/pypoetry/virtualenvs/ai-iwSNfyWa-py3.10/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd3/user/spock/.cache/pypoetry/virtualenvs/ai-iwSNfyWa-py3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(10):\n",
    "    for src,tgt in train_dataloader:\n",
    "        step +=1\n",
    "        src = preproc_src(src).to(device)\n",
    "        tgt = preproc_tgt(tgt).to(device)\n",
    "        \n",
    "        enc_outputs = encoder(src)\n",
    "        decoder_outputs = decoder(tgt[:,:-1], enc_outputs)\n",
    "        loss = F.cross_entropy(decoder_outputs.view(-1, decoder_outputs.shape[-1]), tgt[:,1:].contiguous().view(-1))\n",
    "        if step % 100 == 0:\n",
    "            print(f'e{epoch}:s{step} | loss:{loss:.3f}')\n",
    "        optim1.zero_grad()\n",
    "        # optim2.zero_grad()\n",
    "        loss.backward()\n",
    "        optim1.step()\n",
    "        # optim2.step()\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9335d7d2-f2d6-4e23-9b01-c71e0533fcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src :<bos> Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen <eos>                                                     \n",
      "yhat:<bos> A group of men are working on a truck . <eos>                                                     \n",
      "y   :<bos> A group of men are loading cotton onto a truck <eos>                                                     \n",
      "************************************************************************\n",
      "src :<bos> Ein Mann schläft in einem grünen Raum auf einem Sofa . <eos>                                                   \n",
      "yhat:<bos> A man is sleeping in a green room with a green hair . <eos>                                                  \n",
      "y   :<bos> A man sleeping in a green room on a couch . <eos>                                                    \n",
      "************************************************************************\n",
      "src :<bos> Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau . <eos>                                                   \n",
      "yhat:<bos> A boy with old man sitting on the sidewalk . <eos>                                                     \n",
      "y   :<bos> A boy wearing headphones sits on a woman 's shoulders . <eos>                                                    \n",
      "************************************************************************\n",
      "src :<bos> Zwei Männer bauen eine blaue <unk> auf einem <unk> See auf <eos>                                                   \n",
      "yhat:<bos> Two men are climbing a blue and one of a lake . <eos>                                                   \n",
      "y   :<bos> Two men setting up a blue ice fishing hut on an iced over lake <eos>                                                 \n",
      "************************************************************************\n",
      "src :<bos> Ein Mann mit beginnender Glatze , der eine rote Rettungsweste trägt , sitzt in einem kleinen Boot . <eos>                                            \n",
      "yhat:<bos> A man with a red and a red leotard is wearing a red and white , is sitting in a small black and a small black and white uniform . <eos>                                 \n",
      "y   :<bos> A balding man wearing a red life jacket is sitting in a small boat . <eos>                                                \n",
      "************************************************************************\n",
      "src :<bos> Eine Frau in einem rotem Mantel , die eine vermutlich aus Asien <unk> Handtasche in einem blauen Farbton hält , springt für einen Schnappschuss in die Luft . <eos>                                  \n",
      "yhat:<bos> A woman in a red coat , with a red and blue , wearing a blue and blue , is holding a blue shirt is holding a red and a blue uniform , is holding a red shirt , is wearing a red coat is wearing a red umbrella , wearing blue coat is red and blue coat is wearing blue coat , wearing\n",
      "y   :<bos> A lady in a red coat , holding a bluish hand bag likely of asian descent , jumping off the ground for a <unk> . <eos>                                      \n",
      "************************************************************************\n",
      "src :<bos> Ein brauner Hund rennt dem schwarzen Hund hinterher . <eos>                                                     \n",
      "yhat:<bos> A brown dog is running on a stage . <eos>                                                      \n",
      "y   :<bos> A brown dog is running after the black dog . <eos>                                                     \n",
      "************************************************************************\n",
      "src :<bos> Ein kleiner Junge mit einem <unk> schwingt einen Baseballschläger in Richtung eines ankommenden Balls . <eos>                                               \n",
      "yhat:<bos> A young boy with a red and is leaning against a tree . <eos>                                                  \n",
      "y   :<bos> A young boy wearing a Giants jersey swings a baseball bat at an incoming pitch . <eos>                                               \n",
      "************************************************************************\n",
      "src :<bos> Ein Mann telefoniert in einem unaufgeräumten Büro <eos>                                                       \n",
      "yhat:<bos> A man is holding a piece of paper . <eos>                                                      \n",
      "y   :<bos> A man in a cluttered office is using the telephone <eos>                                                     \n",
      "************************************************************************\n",
      "src :<bos> Eine lächelnde Frau mit einem pfirsichfarbenen Trägershirt hält ein Mountainbike <eos>                                                    \n",
      "yhat:<bos> A smiling woman with a man is holding a microphone . <eos>                                                    \n",
      "y   :<bos> A smiling woman in a peach tank top stands holding a mountain bike <eos>                                                  \n",
      "************************************************************************\n",
      "src :<bos> Ein kleines Kind steht allein auf einem zerklüfteten Felsen . <eos>                                                    \n",
      "yhat:<bos> A young child stands on a rock . <eos>                                                       \n",
      "y   :<bos> A young child is standing alone on some jagged rocks . <eos>                                                    \n",
      "************************************************************************\n",
      "src :<bos> Eine Person auf einem Schneemobil mitten im Sprung . <eos>                                                     \n",
      "yhat:<bos> A person on a bike is a skateboard in a skate park . <eos>                                                  \n",
      "y   :<bos> A person on a snowmobile in mid jump . <eos>                                                      \n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "itos=vocab_transform['en'].get_itos()\n",
    "stoi=vocab_transform['en'].get_stoi()\n",
    "\n",
    "for X,y in test_dataloader:\n",
    "    break\n",
    "X = preproc_src(X).to(device)\n",
    "y = preproc_tgt(y).to(device)\n",
    "\n",
    "y_hat = torch.tensor([[BOS_IDX] + [PAD_IDX]*(BLOCK_SIZE) for _ in range(y.shape[0])]).to(device)\n",
    "for i in range(0,BLOCK_SIZE):\n",
    "    enc_outputs = encoder(X)\n",
    "    decoder_outputs = decoder(y_hat[:,:-1], enc_outputs)\n",
    "    y_hat[:, i+1] = decoder_outputs[:, i].topk(1).indices.flatten()\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    print('src :'+' '.join(vocab_transform['de'].lookup_tokens(X[i].tolist())).replace('<pad>',''))\n",
    "    print('yhat:'+' '.join(vocab_transform['en'].lookup_tokens(y_hat[i].tolist())).replace('<pad>',''))    \n",
    "    print('y   :'+' '.join(vocab_transform['en'].lookup_tokens(y[i].tolist())).replace('<pad>',''))    \n",
    "    print('*'*72)\n",
    "    if i>10:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582d4df-5638-4d73-8199-983437a42f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0c427-e463-4d9f-98c5-9efe8fcb7af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39a451-37ff-40fd-a1b0-cf336f5c8f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755d6f4e-4e16-4994-82ff-ecc554807b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 84K\n",
      "drwxrwxr-x  3 spock spock 4.0K Mar 15 14:10 .\n",
      "drwxrwxr-x 10 spock spock 4.0K Mar 15 12:25 ..\n",
      "drwxrwxr-x  2 spock spock 4.0K Mar 15 14:10 .ipynb_checkpoints\n",
      "-rw-rw-r--  1 spock spock  25K Feb 13 16:48 multi30k_enc_dec.ipynb\n",
      "-rw-rw-r--  1 spock spock  28K Feb 11 16:41 seq2seq_torch-Copy1.ipynb\n",
      "-rw-rw-r--  1 spock spock  16K Feb 10 15:48 seq2seq_v2.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26381daa-ec0f-436d-9617-9828d7ea737b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
