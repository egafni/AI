{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b55b1584-b398-490b-b93e-943a6b64f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from itertools import islice\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d8de78-8f0e-4e36-a029-d282d0f2e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"Thermostatic/parallel_corpus_europarl_english_spanish\")\n",
    "data = data[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f97e698b-b7bc-4901-b409-6d16a677ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316d28ce-8481-4704-9dea-3eb2901a665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[39;1m^0.7.1\u001b[39;22m for \u001b[36mtorchdata\u001b[39m\n",
      "Using version \u001b[39;1m^0.1.1\u001b[39;22m for \u001b[36mspacey\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(3.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(2.0s)\u001b[39;22m\n",
      "\n",
      "\u001b[39;1mPackage operations\u001b[39;22m: \u001b[34m1\u001b[39m install, \u001b[34m0\u001b[39m updates, \u001b[34m0\u001b[39m removals\n",
      "\n",
      "  \u001b[34;1m•\u001b[39;22m \u001b[39mInstalling \u001b[39m\u001b[36mspacey\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m0.1.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mPending...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[39;22m \u001b[39mInstalling \u001b[39m\u001b[36mspacey\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m0.1.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m0%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[39;22m \u001b[39mInstalling \u001b[39m\u001b[36mspacey\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m0.1.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mDownloading...\u001b[39m \u001b[39;1m100%\u001b[39;22m\n",
      "\u001b[1A\u001b[0J  \u001b[34;1m•\u001b[39;22m \u001b[39mInstalling \u001b[39m\u001b[36mspacey\u001b[39m\u001b[39m (\u001b[39m\u001b[39;1m0.1.1\u001b[39;22m\u001b[39m)\u001b[39m: \u001b[34mInstalling...\u001b[39m\n",
      "\u001b[1A\u001b[0J  \u001b[32;1m•\u001b[39;22m \u001b[39mInstalling \u001b[39m\u001b[36mspacey\u001b[39m\u001b[39m (\u001b[39m\u001b[32m0.1.1\u001b[39m\u001b[39m)\u001b[39m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!poetry add torchdata spacey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "248e3919-066a-41d1-b435-e81ba0a6a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3873.18 examples/s]\n"
     ]
    }
   ],
   "source": [
    "source_lang = 'en'\n",
    "target_lang = 'es'\n",
    "prefix = \"translate English to Spanish: \"\n",
    "\n",
    "def preproc(examples):\n",
    "    inputs = [prefix + example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang] ]\n",
    "    return tokenizer(text=inputs, text_target=targets, max_length=128, truncation=True)\n",
    "\n",
    "train_tokenized = data['train'].select(range(100)).map(preproc, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "849542e2-3567-422b-8c92-63ed57b5c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "752a843f-6974-4412-a6ed-2bd849aaa973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50503038-93fb-45a3-b6b5-712f80ffc031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90d5eb-cd62-4296-b0ed-a8b479208f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b1eba4f-cbed-4c4c-b832-e71f6de6d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50841fef-4a25-46e7-a62c-8fc4d9bad112",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f27142b1-148d-45e7-8a9e-4a2eae5c9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0b8601c-3c01-4cdb-9ead-af31738e36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be74fac-a98a-4a46-aa73-769bba3086b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a962db4b-894f-4cfd-8646-30c22f0fa3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_opus_books_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea26d253-265f-4d72-91fb-dac6b8d3bcc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_books' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m----> 4\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtokenized_books\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_books[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m      7\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m      8\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_books' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_books[\"train\"],\n",
    "    eval_dataset=tokenized_books[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74c039-1175-42eb-b2e2-eb0294abf3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
